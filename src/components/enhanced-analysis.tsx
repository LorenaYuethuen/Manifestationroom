import { useState } from 'react';
import type { VisionAnalysis } from '../App';
import { projectId, publicAnonKey } from '../utils/supabase/info';

// ==========================================
// AI è§†è§‰åˆ†æå¼•æ“ - Dual Engine (ModelScope + Claude)
// ==========================================

interface ClaudeVisionResponse {
  visualDNA: {
    colorPalette: string[];
    materials: string[];
    lighting: string;
    spatialFeeling: string;
    emotionalCore: string[];
    archetype: string;
  };
  lifestyleInference: {
    pace: string;
    values: string[];
    dailyRituals: string[];
  };
  sensoryTriggers: {
    smell: string;
    sound: string;
    touch: string;
  };
  sopMapping: {
    module: string; // WRITE_PLAN, PLAN, DO, CHECK
    subSystem: string; // å¯¹åº”å…·ä½“çš„æ•°æ®åº“åç§°
    visualCue: string;
    actions: string[];
  }[];
}

const MS_URL = `https://${projectId}.supabase.co/functions/v1/make-server-dcd239fe/analyze-modelscope`;
const PROXY_URL = `https://${projectId}.supabase.co/functions/v1/make-server-dcd239fe/analyze-proxy`;

// ==========================================
// API Implementations
// ==========================================

async function analyzeVisionWithModelScope(imageFile: File): Promise<ClaudeVisionResponse> {
  const base64Data = await resizeAndConvert(imageFile);
  // Construct Data URL for Qwen-VL (OpenAI Compatible)
  const dataUrl = `data:image/jpeg;base64,${base64Data}`;

  const payload = {
    model: 'Qwen/Qwen-VL-Chat',
    messages: [
      {
        role: 'system',
        content: [
            { type: 'text', text: "ä½ æ˜¯ä¸€ä¸ªåªè¾“å‡ºJSONçš„åŠ©æ‰‹ã€‚å°†æ„¿æ™¯æ¿å›¾ç‰‡è½¬åŒ–ä¸ºSOP JSONæ•°æ®ã€‚ä¸¥ç¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ã€‚" }
        ]
      },
      {
        role: 'user',
        content: [
          {
            type: 'image_url',
            image_url: {
              url: dataUrl
            }
          },
          {
            type: 'text',
            text: VISION_ANALYSIS_PROMPT
          }
        ]
      }
    ]
  };

  const response = await fetch(MS_URL, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${publicAnonKey}`
    },
    body: JSON.stringify(payload)
  });

  const data = await response.json();

  if (data.error) {
     const msg = data.error.message || JSON.stringify(data.error);
     // Handle "Bind Account" error gracefully
     if (msg.includes("bind your Alibaba Cloud account")) {
         console.warn("âš ï¸ ModelScope Account Issue: Account binding required. Automatically falling back to Simulation Mode.");
         throw new Error("TriggerFallback");
     }
     console.error("ModelScope API Error Payload:", data);
     throw new Error(msg);
  }
  
  if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      console.error("ModelScope Unexpected Response:", data);
      throw new Error("Received empty or invalid response from ModelScope.");
  }

  return parseAIResponse(data.choices[0].message.content);
}

// Helper: Resize image to ensure payload fits (Max 1024px)
function resizeAndConvert(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.readAsDataURL(file);
    reader.onload = (event) => {
      const img = new Image();
      img.src = event.target?.result as string;
      img.onload = () => {
        const canvas = document.createElement('canvas');
        const MAX_SIZE = 1024;
        let width = img.width;
        let height = img.height;

        if (width > height) {
          if (width > MAX_SIZE) {
            height *= MAX_SIZE / width;
            width = MAX_SIZE;
          }
        } else {
          if (height > MAX_SIZE) {
            width *= MAX_SIZE / height;
            height = MAX_SIZE;
          }
        }

        canvas.width = width;
        canvas.height = height;
        const ctx = canvas.getContext('2d');
        ctx?.drawImage(img, 0, 0, width, height);
        
        // Output as JPEG with 0.8 quality to reduce size
        const dataUrl = canvas.toDataURL('image/jpeg', 0.8);
        resolve(dataUrl.split(',')[1]);
      };
      img.onerror = reject;
    };
    reader.onerror = reject;
  });
}

async function analyzeVisionWithClaude(imageFile: File, apiKey: string): Promise<ClaudeVisionResponse> {
  const base64Image = await resizeAndConvert(imageFile);
  
  // Standard Claude Messages API Payload
  const payload = {
    model: 'claude-3-5-sonnet-20240620',
    max_tokens: 4000,
    system: "ä½ æ˜¯ä¸€ä¸ªååŠ©ç”¨æˆ·è¿›è¡Œ'ç”Ÿæ´»æ˜¾åŒ–'çš„AIæ¶æ„å¸ˆã€‚ç”¨æˆ·æœ‰ä¸€å¥—å®Œæ•´çš„ LIFE COMPASS ç³»ç»Ÿï¼Œä½ çš„ä»»åŠ¡æ˜¯å°†æ„¿æ™¯æ¿(Mood Board)ä¸­çš„å…ƒç´ ï¼Œä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·çš„ SOP æ¡†æ¶æ‹†è§£å¹¶åˆ†å‘åˆ°å…·ä½“çš„ DATABASE ä¸­ã€‚",
    messages: [
      {
        role: 'user',
        content: [
          {
            type: 'image',
            source: {
              type: 'base64',
              media_type: imageFile.type,
              data: base64Image,
            },
          },
          {
            type: 'text',
            text: VISION_ANALYSIS_PROMPT,
          },
        ],
      },
    ],
  };

  const response = await fetch(PROXY_URL, {
    method: 'POST',
    headers: { 
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${publicAnonKey}`
    },
    body: JSON.stringify({
      provider: 'claude',
      apiKey,
      payload
    })
  });

  const data = await response.json();

  // Handle Claude API Errors
  if (data.error) {
     const msg = data.error.message || JSON.stringify(data.error);
     // Detect billing issues for fallback trigger
     if (msg.includes('credit balance') || msg.includes('too low') || msg.includes('overloaded')) {
         throw new Error(`Billing Error: ${msg}`);
     }
     throw new Error(msg);
  }
  
  if (!data.content || !data.content[0] || !data.content[0].text) {
      console.error("Claude Unexpected Response:", data);
      throw new Error("Received empty or invalid response from Claude.");
  }

  return parseAIResponse(data.content[0].text);
}

function parseAIResponse(text: string): ClaudeVisionResponse {
  try {
    const jsonMatch = text.match(/```json\n([\s\S]*?)\n```/) || text.match(/```\n([\s\S]*?)\n```/);
    if (jsonMatch) return JSON.parse(jsonMatch[1]);
    
    const firstBrace = text.indexOf('{');
    const lastBrace = text.lastIndexOf('}');
    if (firstBrace !== -1 && lastBrace !== -1) return JSON.parse(text.substring(firstBrace, lastBrace + 1));
    
    return JSON.parse(text);
  } catch (e) {
    // console.log("JSON Parse Failed. Raw Output length:", text.length);
    throw new Error("TriggerFallback");
  }
}

// ==========================================
// AI Prompt Template
// ==========================================

const VISION_ANALYSIS_PROMPT = `
ä½ æ˜¯ä¸€ä¸ªçº¯ç²¹çš„ JSON æ•°æ®ç”Ÿæˆå™¨ã€‚è¯·åˆ†æè¿™å¼ æ„¿æ™¯å›¾ç‰‡(MOOD BOARD)ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºç”¨æˆ· LIFE COMPASS ç³»ç»Ÿä¸­çš„å…·ä½“å…ƒç´ ã€‚

âš ï¸ æå…¶é‡è¦ï¼š
1. ç›´æ¥è¾“å‡º JSON ä»£ç ï¼Œä¸è¦åŒ…å« markdown \`\`\`json æ ‡è®°ã€‚
2. ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€å‰è¨€æˆ–ç»“è¯­ã€‚
3. å¿…é¡»ä¸¥æ ¼éµå®ˆ JSON æ ¼å¼ã€‚

ç”¨æˆ·çš„ **SOP ç³»ç»Ÿæ¶æ„** å¦‚ä¸‹ï¼š

1. **WRITE_PLAN (æ”¶é›†ä¸çµæ„Ÿ)**
   - å¯¹åº”æ¨¡å—: **æ”¶é›†ç®±**
   - åŠ¨ä½œ: æå–æ„¿æ™¯ä¸­çš„æ ¸å¿ƒä»·å€¼ã€æè´¨ã€è‰²å½©ï¼Œæ”¾å…¥æ”¶é›†ç®±ã€‚

2. **PLAN (ç›®æ ‡ä¸æ‹†è§£)**
   - å¯¹åº”æ¨¡å—: **OKRåŠé¡¹ç›®ç®¡ç†**
   - æ•°æ®åº“: ç›®æ ‡ç®¡ç†(Goals), å…³é”®æˆæœ(Key Results), ç›®æ ‡å‘¨æœŸ.
   - åŠ¨ä½œ: å°†æ„¿æ™¯è½¬åŒ–ä¸ºå…·ä½“çš„OKRã€‚

3. **DO (æ‰§è¡Œä¸è½åœ° - DATABASE åˆ†å‘)**
   è¯·å°†è¯†åˆ«å‡ºçš„å…ƒç´ åˆ†å‘åˆ°ä»¥ä¸‹å…·ä½“æ•°æ®åº“ï¼š
   - **ç‰©å“åº“å­˜**: ç”Ÿæ´»ç‰©å“åº“å­˜, æ”¶æ”¯ç®¡ç†, Finance (å¦‚: è´­ä¹°ç‰¹å®šæè´¨çš„å®¶å…·).
   - **ç”Ÿæ´»ä¹ æƒ¯**: Health, å¥èº«è¿åŠ¨ç®¡ç† 2.0, ä¹ æƒ¯è¿½è¸ªå™¨.
   - **è¿åŠ¨é¥®é£Ÿ**: è¥å…»ä¸å¥åº·, é¥®é£Ÿè®¡åˆ’å™¨, Workout (å¦‚: åŸå‹é£Ÿç‰©, éª‘è¡Œ).
   - **æ´»åŠ¨è®¡åˆ’**: æ´»åŠ¨ä¸æ—…è¡Œè®¡åˆ’, è¡Œå‰å‡†å¤‡æ¸…å• (å¦‚: æ¢åº—, æ—…è¡Œ).
   - **è¾“å‡ºåˆ›é€ **: äº‘çœ‹ç§€, R.I.A. é˜…è¯»ç³»ç»Ÿ, å†…å®¹åˆ›ä½œç³»ç»Ÿ.
   - **å­¦ä¹ è¿›åº¦**: çŸ¥è¯†ç®¡ç†, Heptabase, Learn.
   - **GTDç®¡ç†**: é¡¹ç›®ç®¡ç†, ä»»åŠ¡ç®¡ç†, Projects.

4. **CHECK (å¤ç›˜ä¸çº å)**
   - å¯¹åº”æ¨¡å—: **å›é¡¾çº å**
   - åŠ¨ä½œ: è®¾å®šå¤ç›˜å‘¨æœŸ(æ¯æ—¥/å‘¨/æœˆ)å¯¹ç…§ MOOD BOARDã€‚

5. **LIFESTYLE (ç”Ÿæ´»æ–¹å¼ - DAILY_ROUTINE)**
   ç”¨æˆ·å›ºå®šçš„ Routine ç»“æ„ï¼Œè¯·å°†æ„¿æ™¯å…ƒç´ èå…¥å…¶ä¸­ï¼š
   - **æ™šä¸Šç¡å‰**: å†¥æƒ³, é˜…è¯»(å¬ä½›ä¹), å‡†å¤‡æ˜æ—¥è£…å¤‡/é£Ÿç‰©(æ³¡è±†å­/æ´—ç‰ç±³).
   - **æ—©ä¸Šè‡ªç„¶é†’**: å†¥æƒ³(é‡‘åˆšç»), æ—©é¤(æ‰“è±†æµ†/è’¸çº¢è–¯/ç…®é¸¡è›‹), å…«æ®µé”¦/ç‘œä¼½, å­¦ä¹ 1å°æ—¶(ä¸“ä¸šçŸ¥è¯†).
   - **å·¥ä½œæ—¥**: éª‘è½¦é€šå‹¤(è‡ªç„¶å‡ºæ±—), ä¸‹ç­æ— æ°§, å¤ç›˜15åˆ†é’Ÿ.
   - **å‘¨æœ«**: éª‘è¡Œ+å’–å•¡é¦†é˜…è¯», æ”€å²©, è§‚å½±è¾“å‡º, å¤‡é¤(æ›´æ–°é£Ÿè°±).

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š

\`\`\`json
{
  "visualDNA": {
    "colorPalette": ["#Hex", "#Hex"],
    "materials": ["æè´¨1", "æè´¨2"],
    "lighting": "å…‰çº¿æè¿°",
    "spatialFeeling": "ç©ºé—´æ„Ÿå—",
    "emotionalCore": ["æƒ…æ„Ÿ1", "æƒ…æ„Ÿ2"],
    "archetype": "ç”Ÿæ´»åŸå‹ (å¦‚: 'Mediterranean Slow Life')"
  },
  "lifestyleInference": {
    "pace": "ç”Ÿæ´»èŠ‚å¥",
    "values": ["æ ¸å¿ƒä»·å€¼1", "æ ¸å¿ƒä»·å€¼2"],
    "dailyRituals": ["ä»ªå¼æ„Ÿè¡Œä¸º1", "ä»ªå¼æ„Ÿè¡Œä¸º2"]
  },
  "sensoryTriggers": {
    "smell": "å—…è§‰",
    "sound": "å¬è§‰",
    "touch": "è§¦è§‰"
  },
  "sopMapping": [
    {
      "module": "WRITE_PLAN",
      "subSystem": "æ”¶é›†ç®±",
      "visualCue": "å›¾ç‰‡ä¸­çš„...",
      "actions": ["å°†...çµæ„ŸåŠ å…¥æ”¶é›†ç®±", "å®šä¹‰æ„¿æ™¯å…³é”®è¯..."]
    },
    {
      "module": "PLAN",
      "subSystem": "OKRåŠé¡¹ç›®ç®¡ç†",
      "visualCue": "...",
      "actions": ["è®¾å®šç›®æ ‡: ...", "KR: æ¯å‘¨å®Œæˆ..."]
    },
    {
      "module": "DO",
      "subSystem": "ç”Ÿæ´»ç‰©å“åº“å­˜", 
      "visualCue": "...",
      "actions": ["é‡‡è´­...æè´¨çš„ç‰©å“", "æ•´ç†...åŒºåŸŸ"]
    },
    {
      "module": "DO",
      "subSystem": "è¥å…»ä¸å¥åº·",
      "visualCue": "...",
      "actions": ["å°è¯•...é£Ÿè°±", "å‡†å¤‡...é£Ÿæ"]
    },
    {
      "module": "DO",
      "subSystem": "R.I.A. é˜…è¯»ç³»ç»Ÿ",
      "visualCue": "...",
      "actions": ["é˜…è¯»...ä¸»é¢˜ä¹¦ç±", "è¾“å‡ºç¬”è®°"]
    },
    {
      "module": "DO",
      "subSystem": "æ´»åŠ¨ä¸æ—…è¡Œè®¡åˆ’",
      "visualCue": "...",
      "actions": ["è®¡åˆ’å»...æ¢åº—", "å®‰æ’...æ—…è¡Œ"]
    },
    {
      "module": "CHECK",
      "subSystem": "å›é¡¾çº å",
      "visualCue": "...",
      "actions": ["æ¯å‘¨å¯¹æ¯”æ„¿æ™¯å›¾...", "æ£€æŸ¥ä¹ æƒ¯æ‰§è¡Œç‡"]
    }
  ]
}
\`\`\`
`;

function fileToBase64(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => resolve((reader.result as string).split(',')[1]);
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

export function useVisionAnalysis() {
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [progress, setProgress] = useState(0);
  const [results, setResults] = useState<VisionAnalysis[]>([]);

  const analyzeImages = async (files: File[]) => {
    setIsAnalyzing(true);
    setProgress(0);
    const analyses: VisionAnalysis[] = [];
    
    // Retrieve User Key if available
    const claudeKey = localStorage.getItem('anthropic_api_key');

    for (let i = 0; i < files.length; i++) {
      try {
        let aiResult: ClaudeVisionResponse | undefined;
        
        if (files[i].name === "My_Vision_Board_Demo.png") {
           aiResult = getDemoMockResponse();
        } else {
           // STRATEGY: 
           // 1. If User has Claude Key -> Try Claude
           // 2. If Claude fails with Auth/Billing -> Fallback to Mock
           // 3. If no Claude Key -> Try ModelScope
           // 4. If ModelScope fails -> Fallback to Mock

           if (claudeKey && claudeKey.startsWith('sk-')) {
               try {
                  console.log(`ğŸ¤– Starting Analysis with Claude... Image ${i+1}/${files.length}`);
                  aiResult = await analyzeVisionWithClaude(files[i], claudeKey);
               } catch (claudeError: any) {
                  const msg = claudeError.message?.toLowerCase() || '';
                  if (msg.includes('credit balance') || msg.includes('billing') || msg.includes('too low')) {
                      console.warn("âš ï¸ Claude Billing Issue detected. Falling back to Safe Mode (Mock).");
                      // Do NOT try ModelScope here, go straight to Mock as per user requirement for "Silent Fallback"
                      throw new Error("TriggerFallback"); 
                  } else {
                      console.error("Claude Error:", claudeError);
                      // If it's a technical error, maybe we try ModelScope?
                      // For now, let's keep it simple and fallback to Mock to be safe.
                      throw new Error("TriggerFallback");
                  }
               }
           } else {
               // No Claude Key, try ModelScope (Server Key)
               try {
                  console.log(`ğŸ¤– Starting Analysis with ModelScope (Qwen-VL)... Image ${i+1}/${files.length}`);
                  aiResult = await analyzeVisionWithModelScope(files[i]);
               } catch (msError: any) {
                  if (msError.message !== "TriggerFallback") {
                      console.error("ModelScope Error:", msError);
                  }
                  throw new Error("TriggerFallback");
               }
           }
        }
        
        if (!aiResult) {
            throw new Error("No result from AI");
        }
        
        analyses.push({
          id: `vision-${Date.now()}-${i}`,
          imageUrl: URL.createObjectURL(files[i]),
          uploadedAt: Date.now(),
          visualDNA: aiResult.visualDNA,
          lifestyleInference: aiResult.lifestyleInference,
          sensoryTriggers: aiResult.sensoryTriggers,
          sopMapping: aiResult.sopMapping,
          manifestationPath: generateManifestationPath(aiResult),
        });
        setProgress(((i + 1) / files.length) * 100);

      } catch (error: any) {
        // Fallback to Simulation Mode
        const msg = error.message || '';
        if (msg !== "TriggerFallback") {
             console.warn(`Analysis failed details:`, error);
        }
        console.log("âš ï¸ Falling back to Simulation Mode.");
        analyses.push(await generateFallbackAnalysis(files[i], i));
      }
    }
    setResults(analyses);
    setIsAnalyzing(false);
    return analyses;
  };

  return { analyzeImages, isAnalyzing, progress, results };
}

function generateManifestationPath(aiResult: ClaudeVisionResponse) {
  return [
    {
      week: 1,
      focus: 'WRITE & PLAN (æ”¶é›†ä¸å®šæº)',
      actions: [
        aiResult.sopMapping.find(m => m.module === 'WRITE_PLAN')?.actions[0] || 'æ›´æ–°æ”¶é›†ç®±',
        aiResult.sopMapping.find(m => m.module === 'PLAN')?.actions[0] || 'è®¾å®šæœ¬æœˆOKR',
      ],
    },
    {
      week: 2,
      focus: 'DO: ç©ºé—´ä¸ç‰©å“ (Inventory)',
      actions: [
        aiResult.sopMapping.find(m => m.subSystem === 'ç”Ÿæ´»ç‰©å“åº“å­˜')?.actions[0] || 'æ¸…ç†ç©ºé—´',
        'æ–­èˆç¦»ä¸ç¬¦ç‰©å“',
      ],
    },
    {
      week: 3,
      focus: 'DO: ä¹ æƒ¯ä¸å¥åº· (Routine)',
      actions: [
        aiResult.sopMapping.find(m => m.subSystem === 'è¥å…»ä¸å¥åº·')?.actions[0] || 'ä¼˜åŒ–æ™¨é—´ä»ªå¼',
        'æ‰§è¡Œæ¯æ—¥éª‘è¡Œ/è¿åŠ¨',
      ],
    },
    {
      week: 4,
      focus: 'CHECK & OUTPUT (åˆ›é€ ä¸å¤ç›˜)',
      actions: [
        aiResult.sopMapping.find(m => m.subSystem === 'R.I.A. é˜…è¯»ç³»ç»Ÿ')?.actions[0] || 'Heptabase è¾“å‡º',
        aiResult.sopMapping.find(m => m.module === 'CHECK')?.actions[0] || 'æœˆåº¦å¤ç›˜',
      ],
    },
  ];
}

function getDemoMockResponse(): ClaudeVisionResponse {
  return {
    visualDNA: {
      colorPalette: ['#E8DCC4', '#C9A882', '#8B7355'],
      materials: ['Terra Cotta', 'Linen', 'Wood', 'Brass'],
      lighting: 'Warm Morning Light',
      spatialFeeling: 'Mediterranean Slow Life',
      emotionalCore: ['Calm', 'Grounded', 'Intentional'],
      archetype: 'Mediterranean Creator'
    },
    lifestyleInference: {
      pace: 'Slow & Intentional',
      values: ['Quality over Quantity', 'Handmade over Industrial', 'Present moment'],
      dailyRituals: ['Morning barefoot meditation', 'Hand-pour coffee ritual', 'Candlelight reflection']
    },
    sensoryTriggers: {
      smell: 'Fresh rosemary & Coffee',
      sound: 'Breeze in linen curtains',
      touch: 'Rough terra cotta & Smooth wood'
    },
    sopMapping: [
      {
        module: 'WRITE_PLAN',
        subSystem: 'æ”¶é›†ç®±',
        visualCue: 'æ•´ä½“æ°›å›´',
        actions: ['å°†"åœ°ä¸­æµ·æ…¢ç”Ÿæ´»"æ„¿æ™¯å›¾å­˜å…¥æ”¶é›†ç®±', 'æå–"é™¶åœŸ/äºšéº»"å…³é”®è¯']
      },
      {
        module: 'PLAN',
        subSystem: 'OKRåŠé¡¹ç›®ç®¡ç†',
        visualCue: 'ç”Ÿæ´»æ–¹å¼è½¬å˜',
        actions: ['è®¾å®šç›®æ ‡: æ‰“é€ åœ°ä¸­æµ·é£æ ¼å±…å®¶ç©ºé—´', 'KR: æ›´æ¢æ‰€æœ‰å¡‘æ–™å®¹å™¨ä¸ºé™¶/æœ¨æè´¨']
      },
      {
        module: 'DO',
        subSystem: 'ç”Ÿæ´»ç‰©å“åº“å­˜',
        visualCue: 'æè´¨ç»†èŠ‚',
        actions: ['é‡‡è´­æ‰‹å·¥é™¶ç¢—å’Œæœ¨ç §æ¿', 'æ–­ï¿½ï¿½ï¿½ç¦»åŒ–çº¤è¡£ç‰©ï¼Œè´­å…¥äºšéº»å®¶å±…æœ']
      },
      {
        module: 'DO',
        subSystem: 'è¥å…»ä¸å¥åº·',
        visualCue: 'é¥®é£Ÿæš—ç¤º',
        actions: ['å»ºç«‹"æ…¢é£Ÿä»ªå¼": æ¯é¤å‰5åˆ†é’Ÿæ„Ÿæ©', 'å‡†å¤‡å…¨è°·ç‰©ä¸æ©„æ¦„æ²¹é£Ÿè°±']
      },
      {
        module: 'DO',
        subSystem: 'R.I.A. é˜…è¯»ç³»ç»Ÿ',
        visualCue: 'çŸ¥è¯†æ°›å›´',
        actions: ['é˜…è¯»ã€ŠWabi-Sabiã€‹ä¸æè´¨ç¾å­¦ä¹¦ç±', 'åœ¨ Heptabase è¾“å‡ºé˜…è¯»ç¬”è®°']
      },
      {
        module: 'DO',
        subSystem: 'æ´»åŠ¨ä¸æ—…è¡Œè®¡åˆ’',
        visualCue: 'æ–‡åŒ–æš—ç¤º',
        actions: ['å‘¨æœ«æ¢è®¿æœ¬åœ°é™¶è‰ºå·¥ä½œå®¤', 'è®¡åˆ’ä¸€æ¬¡åœ°ä¸­æµ·æ–‡åŒ–ç›¸å…³çš„æ—…è¡Œ']
      },
      {
        module: 'CHECK',
        subSystem: 'å›é¡¾çº å',
        visualCue: 'ä¸€è‡´æ€§',
        actions: ['æ¯æ—¥å¯¹æ¯”ç©ºé—´ç…§ç‰‡ä¸æ„¿æ™¯å›¾', 'å¤ç›˜ DAILY_ROUTINE æ‰§è¡Œç‡']
      }
    ]
  };
}

// ==========================================
// MOCK DATA PROFILES (Based on User's Vision)
// ==========================================

const MOCK_PROFILES: ClaudeVisionResponse[] = [
    // 1. Mediterranean Elegance (Index 0, 2, etc.)
    {
        visualDNA: {
          colorPalette: ["#F5F0E8", "#8B6F47", "#FFFFFF", "#2C2420"],
          materials: ["Terra Cotta", "Raw Concrete", "Linen", "Vintage Wood"],
          lighting: "Golden Hour Diffused",
          spatialFeeling: "Expansive yet Intimate",
          emotionalCore: ["Confident", "Sensual", "Unhurried", "Theatrical"],
          archetype: "Mediterranean Muse"
        },
        lifestyleInference: {
          pace: "Slow Mornings (9-11am)",
          values: ["Beauty as Daily Life", "Body as Art", "Space as Stage"],
          dailyRituals: ["Barefoot Grounding", "Natural Light Yoga", "Candlelight Dinner"]
        },
        sensoryTriggers: {
          smell: "Fig & Old Wood",
          sound: "Distant Bells & Fabric Rustle",
          touch: "Cool Terra Cotta & Soft Linen"
        },
        sopMapping: [
          { module: 'WRITE_PLAN', subSystem: 'æ”¶é›†ç®±', visualCue: 'Aesthetic', actions: ['Remove plastic items', 'Add linen to wishlist'] },
          { module: 'PLAN', subSystem: 'OKRåŠé¡¹ç›®ç®¡ç†', visualCue: 'Upgrade', actions: ['Target: Aesthetic Upgrade', 'KR: Replace 3 synthetic items'] },
          { module: 'DO', subSystem: 'ç”Ÿæ´»ç‰©å“åº“å­˜', visualCue: 'Materials', actions: ['Buy Linen Bedding', 'Buy Vintage Chair'] },
          { module: 'DO', subSystem: 'å¥èº«è¿åŠ¨ç®¡ç† 2.0', visualCue: 'Body', actions: ['Pilates 3x/week', 'Practice Conscious Posture'] },
          { module: 'DO', subSystem: 'å†…å®¹åˆ›ä½œç³»ç»Ÿ', visualCue: 'Light', actions: ['Photo Shoot: Light & Shadow', 'Study Helmut Newton'] },
          { module: 'CHECK', subSystem: 'å›é¡¾çº å', visualCue: 'Review', actions: ['Daily Body Feeling Journal'] }
        ]
    },
    // 2. Urban Minimalist (Index 1)
    {
        visualDNA: {
          colorPalette: ["#4A3C2E", "#1C1C1C", "#D4C5B0"],
          materials: ["Wool", "Stone", "Aged Architecture"],
          lighting: "Overcast Diffused",
          emotionalCore: ["Introspective", "Independent", "Intellectual"],
          archetype: "Urban FlÃ¢neur"
        },
        lifestyleInference: {
          pace: "Observational & Solitary",
          values: ["Intellectual Depth", "Minimalism", "Observation"],
          dailyRituals: ["Afternoon City Walk", "Cafe Reading", "People Watching"]
        },
        sensoryTriggers: {
          smell: "Rain on Asphalt",
          sound: "City Hum",
          touch: "Rough Wool & Cold Stone"
        },
        sopMapping: [
           { module: 'WRITE_PLAN', subSystem: 'æ”¶é›†ç®±', visualCue: 'Urban', actions: ['Capture city textures', 'Note observation ideas'] },
           { module: 'DO', subSystem: 'ç”Ÿæ´»ç‰©å“åº“å­˜', visualCue: 'Wardrobe', actions: ['Keep 5 High-Quality Coats', 'Declutter Wardrobe'] },
           { module: 'DO', subSystem: 'R.I.A. é˜…è¯»ç³»ç»Ÿ', visualCue: 'Intellect', actions: ['Read Philosophy Books', 'Cafe Reading Session'] },
           { module: 'DO', subSystem: 'å†…å®¹åˆ›ä½œç³»ç»Ÿ', visualCue: 'People', actions: ['Observation Journal: Stranger Stories'] },
           { module: 'CHECK', subSystem: 'å›é¡¾çº å', visualCue: 'Solitude', actions: ['Weekly Solitude Audit'] }
        ]
    },
    // 3. Wabi-Sabi Sanctuary (Index 3, 6, 7)
    {
        visualDNA: {
          colorPalette: ["#C4A574", "#8B7355", "#3D3D3D"],
          materials: ["Raw Concrete", "Natural Wood", "Linen"],
          lighting: "Warm Ambient Layers",
          spatialFeeling: "Low Profile Zen Flow",
          emotionalCore: ["Grounded", "Meditative", "Uncluttered"],
          archetype: "Wabi-Sabi Essentialist"
        },
        lifestyleInference: {
          pace: "Grounded & Present",
          values: ["Imperfection", "Silence", "Nature"],
          dailyRituals: ["Floor Tea Ceremony", "Floor Reading", "Nothing Time"]
        },
        sensoryTriggers: {
          smell: "Earth & Tea",
          sound: "Silence",
          touch: "Raw Wood Texture"
        },
        sopMapping: [
           { module: 'DO', subSystem: 'ç”Ÿæ´»ç‰©å“åº“å­˜', visualCue: 'Simplicity', actions: ['One-In-One-Out Rule', 'Lower Furniture Height'] },
           { module: 'DO', subSystem: 'ä¹ æƒ¯è¿½è¸ªå™¨', visualCue: 'Living', actions: ['Floor Living Day', 'Remove Ceiling Lights'] },
           { module: 'DO', subSystem: 'Finance', visualCue: 'Craft', actions: ['Invest in Handmade Crafts', 'Stop Impulse Buying'] },
           { module: 'CHECK', subSystem: 'å›é¡¾çº å', visualCue: 'Space', actions: ['Declutter Check', 'Silence Audit'] }
        ]
    },
    // 4. Coffee Ritual Corner (Index 4)
    {
        visualDNA: {
          colorPalette: ["#3C3C3C", "#000000", "#A88B6F"],
          materials: ["Steel", "Glass", "Dark Wood"],
          lighting: "Focused Spot",
          spatialFeeling: "Precision Corner",
          emotionalCore: ["Precision", "Self Care", "Focus"],
          archetype: "Ritual Master"
        },
        lifestyleInference: {
          pace: "Precise & Slow Start",
          values: ["Process", "Quality", "Patience"],
          dailyRituals: ["Morning Pour Over", "Bean Grinding", "Tech-Free Morning"]
        },
        sensoryTriggers: {
          smell: "Fresh Ground Coffee",
          sound: "Water Pouring",
          touch: "Warm Ceramic Cup"
        },
        sopMapping: [
           { module: 'DO', subSystem: 'ä¹ æƒ¯è¿½è¸ªå™¨', visualCue: 'Morning', actions: ['06:30 Coffee Ceremony', 'No Phone during Coffee'] },
           { module: 'DO', subSystem: 'ç”Ÿæ´»ç‰©å“åº“å­˜', visualCue: 'Gear', actions: ['Setup Coffee Corner', 'Buy Pour Over Gear'] },
           { module: 'DO', subSystem: 'çŸ¥è¯†ç®¡ç†', visualCue: 'Taste', actions: ['Study Coffee Origins', 'Tasting Notes Log'] }
        ]
    },
    // 5. Quiet Companionship (Index 5)
    {
        visualDNA: {
          colorPalette: ["#E0E0E0", "#303030", "#A0A0A0"],
          materials: ["Soft Light", "Paper", "Fur"],
          lighting: "Window Blinds Shadow",
          spatialFeeling: "Shared Solitude",
          emotionalCore: ["Solitude", "Connection", "Peace"],
          archetype: "Silent Companion"
        },
        lifestyleInference: {
          pace: "Gentle & Shared",
          values: ["Quiet Presence", "Deep Connection", "Peace"],
          dailyRituals: ["Silent Reading Hour", "Cat Meditation", "Window Gazing"]
        },
        sensoryTriggers: {
          smell: "Clean Laundry",
          sound: "Turning Pages",
          touch: "Soft Fur"
        },
        sopMapping: [
           { module: 'DO', subSystem: 'æ´»åŠ¨ä¸æ—…è¡Œè®¡åˆ’', visualCue: 'Social', actions: ['Practice Silent Company', 'Invite Friend for "Nothing"'] },
           { module: 'DO', subSystem: 'R.I.A. é˜…è¯»ç³»ç»Ÿ', visualCue: 'Focus', actions: ['Daily Quality Solitude', 'Paper Book Reading'] }
        ]
    }
];

async function generateFallbackAnalysis(file: File, index: number): Promise<VisionAnalysis> {
  await new Promise(resolve => setTimeout(resolve, 800)); // Slight delay for realism
  
  // Select profile based on index to rotate through them
  let profileIndex = 0;
  const modIndex = index % 8; // Assuming 8 images cycle
  
  if (modIndex === 0 || modIndex === 2) profileIndex = 0;
  else if (modIndex === 1) profileIndex = 1;
  else if (modIndex === 3 || modIndex === 6 || modIndex === 7) profileIndex = 2;
  else if (modIndex === 4) profileIndex = 3;
  else if (modIndex === 5) profileIndex = 4;
  
  const mockProfile = MOCK_PROFILES[profileIndex];

  return {
    id: `vision-simulated-${Date.now()}-${index}`,
    imageUrl: URL.createObjectURL(file),
    uploadedAt: Date.now(),
    visualDNA: mockProfile.visualDNA,
    lifestyleInference: mockProfile.lifestyleInference,
    sensoryTriggers: mockProfile.sensoryTriggers,
    sopMapping: mockProfile.sopMapping,
    manifestationPath: generateManifestationPath(mockProfile)
  };
}

export default { analyzeVisionWithModelScope, useVisionAnalysis };